{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5999ba94",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "21c4148e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'rand = torch.randn(4, 3, 64, 64)\\npred_noise = torch.randn_like(rand)\\nrandtime = torch.randint(0, 1000, (4,))\\nsampler.remove_noise(image=rand, timesteps=randtime, predicted_noise=pred_noise)'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Sampler:\n",
        "    def __init__(self, num_steps=1000, beta_start=0.0001, beta_end=0.02):\n",
        "        self.num_steps = num_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.beta_schedule = self.linear_beta_schedule()\n",
        "        self.alpha = 1 - self.beta_schedule\n",
        "        self.alpha_cummulative_prod = torch.cumprod(self.alpha, dim=-1)\n",
        "\n",
        "    def linear_beta_schedule(self):\n",
        "        return torch.linspace(self.beta_start, self.beta_end, self.num_steps)\n",
        "\n",
        "    def _repeated_unsqueeze(self, target, tensor):\n",
        "        while target.dim() > tensor.dim():\n",
        "            tensor = tensor.unsqueeze(-1)\n",
        "        return tensor\n",
        "\n",
        "    def add_noise(self, image, timesteps):\n",
        "        batch_size, c, h, w = image.shape\n",
        "        device = image.device\n",
        "        alpha_cummulative_prod_timesteps = self.alpha_cummulative_prod[timesteps].to(\n",
        "            device\n",
        "        )\n",
        "        mean_coeff = alpha_cummulative_prod_timesteps**0.5\n",
        "        var_coeff = (1 - alpha_cummulative_prod_timesteps) ** 0.5\n",
        "        mean_coeff = self._repeated_unsqueeze(image, mean_coeff)\n",
        "        var_coeff = self._repeated_unsqueeze(image, var_coeff)\n",
        "        noise = torch.randn_like(image)\n",
        "        \"\"\"print(mean_coeff.shape)\n",
        "        print(image.shape)\"\"\"\n",
        "        noisy_image = mean_coeff * image + var_coeff * noise\n",
        "        return noisy_image, noise\n",
        "\n",
        "    def remove_noise(self, image, timesteps, predicted_noise):\n",
        "        b, c, h, w = image.shape\n",
        "        device = image.device\n",
        "        equal_to_zero_mask = timesteps == 0\n",
        "        beta_t = self.beta_schedule[timesteps].to(device)\n",
        "        alpha_t = self.alpha[timesteps].to(device)\n",
        "        alpha_cummulative_prod_t = self.alpha_cummulative_prod[timesteps].to(device)\n",
        "        alpha_cummulative_prod_t_prev = self.alpha_cummulative_prod[timesteps - 1].to(\n",
        "            device\n",
        "        )\n",
        "        alpha_cummulative_prod_t_prev[equal_to_zero_mask] = (\n",
        "            1.0  # @QUESTION: this line of code looks weird\n",
        "        )\n",
        "        noise = torch.randn_like(\n",
        "            image\n",
        "        )  # This is element z in line 4 in Algorithm 2 Sampling\n",
        "        variance = (\n",
        "            beta_t\n",
        "            * (1 - alpha_cummulative_prod_t_prev)\n",
        "            / (1 - alpha_cummulative_prod_t)\n",
        "        )  # This is element beta_t_hat in formula (7)\n",
        "        variance = self._repeated_unsqueeze(image, variance)\n",
        "        sigma_t_z = (\n",
        "            variance**0.5\n",
        "        ) * noise  # This is element sigma * z in line 4 in Algorithm 2 Sampling\n",
        "        noise_coff = (\n",
        "            beta_t / (1 - alpha_cummulative_prod_t) ** 0.5\n",
        "        )  # This is an element in line 4 in Algorithm 2 Sampling, in the paper, they write beta_t in form of (1 - alpha_t)\n",
        "        noise_coff = self._repeated_unsqueeze(image, noise_coff)\n",
        "        reciprocal_root_alpha_t = alpha_t ** (\n",
        "            -0.5\n",
        "        )  # This is the first element in Algorithm 2 Sampling\n",
        "        reciprocal_root_alpha_t = self._repeated_unsqueeze(\n",
        "            image, reciprocal_root_alpha_t\n",
        "        )\n",
        "\n",
        "        # Final formula in Algorithm 2 Sampling\n",
        "        mean = reciprocal_root_alpha_t * (image - noise_coff * predicted_noise)\n",
        "        denoised = mean + sigma_t_z\n",
        "\n",
        "        return denoised\n",
        "\n",
        "\n",
        "sampler = Sampler()\n",
        "\"\"\"rand = torch.randn(4, 3, 64, 64)\n",
        "pred_noise = torch.randn_like(rand)\n",
        "randtime = torch.randint(0, 1000, (4,))\n",
        "sampler.remove_noise(image=rand, timesteps=randtime, predicted_noise=pred_noise)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8a1d745f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels, num_heads=12, attn_p=0, proj_p=0):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = in_channels // num_heads\n",
        "        self.scale = self.head_dim ** (-0.5)  # 1 / sqrt(d)\n",
        "        self.query = nn.Linear(in_channels, in_channels)\n",
        "        self.key = nn.Linear(in_channels, in_channels)\n",
        "        self.value = nn.Linear(in_channels, in_channels)\n",
        "        self.attn_p = attn_p\n",
        "        self.proj = nn.Linear(in_channels, in_channels)\n",
        "        self.proj_drop = nn.Dropout(proj_p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, embed_dim = x.shape\n",
        "        q = (\n",
        "            self.query(x)\n",
        "            .reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "            .transpose(1, 2)\n",
        "        )\n",
        "        k = (\n",
        "            self.key(x)\n",
        "            .reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "            .transpose(1, 2)\n",
        "        )\n",
        "        v = (\n",
        "            self.value(x)\n",
        "            .reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "            .transpose(1, 2)\n",
        "        )\n",
        "        x = F.scaled_dot_product_attention(q, k, v, dropout_p=self.attn_p)\n",
        "        x = x.transpose(1, 2).reshape(batch_size, seq_len, embed_dim)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        \"\"\"print(x.shape)\"\"\"\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_channels, mlp_ratio=4, mlp_p=0):\n",
        "        super().__init__()\n",
        "        self.fc_1 = nn.Linear(in_channels, in_channels * mlp_ratio)\n",
        "        self.act = nn.GELU()\n",
        "        self.drop_1 = nn.Dropout(mlp_p)\n",
        "        self.fc_2 = nn.Linear(in_channels * mlp_ratio, in_channels)\n",
        "        self.drop_2 = nn.Dropout(mlp_p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc_1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop_1(x)\n",
        "        x = self.fc_2(x)\n",
        "        x = self.drop_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels, num_heads=4, mlp_ratio=2, proj_p=0, attn_p=0, mlp_p=0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.norm_1 = nn.LayerNorm(\n",
        "            in_channels, eps=1e-6\n",
        "        )  # @QUESTION: what does eps mean?\n",
        "        self.attn = SelfAttention(\n",
        "            in_channels=in_channels, num_heads=num_heads, attn_p=attn_p, proj_p=proj_p\n",
        "        )\n",
        "        self.norm_2 = nn.LayerNorm(in_channels, eps=1e-6)\n",
        "        self.mlp = MLP(in_channels=in_channels, mlp_ratio=mlp_ratio, mlp_p=mlp_p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape  # batch_size, channels, height, weight\n",
        "        x = x.reshape(b, c, h * w).permute(0, 2, 1)  # Swap dim 1 anf dim 2\n",
        "        x = x + self.attn(self.norm_1(x))\n",
        "        x = x + self.mlp(self.norm_2(x))\n",
        "        x = x.permute(0, 2, 1).reshape(b, c, h, w)\n",
        "        return x\n",
        "\n",
        "\n",
        "rand = torch.randn(4, 64, 14, 14)\n",
        "t = TransformerBlock(in_channels=64, num_heads=4)\n",
        "\"\"\"t(rand).shape\"\"\"\n",
        "output = t(rand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "62c0e52f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SinusoidalTimeEmbedding(nn.Module):\n",
        "    def __init__(self, time_embed_dim, scaled_time_embed_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # This one is untrainable\n",
        "        self.inv_freq = nn.Parameter(\n",
        "            1.0\n",
        "            / (10000 ** (torch.arange(0, time_embed_dim, 2).float() / time_embed_dim)),\n",
        "            requires_grad=False,\n",
        "        )\n",
        "\n",
        "        # This one is trainable\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.Linear(time_embed_dim, scaled_time_embed_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(scaled_time_embed_dim, scaled_time_embed_dim),\n",
        "            nn.SiLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, timesteps: torch.Tensor):\n",
        "        timestep_freqs = timesteps.unsqueeze(1) * self.inv_freq.unsqueeze(0)\n",
        "        embeddings = torch.cat(\n",
        "            [torch.sin(timestep_freqs), torch.cos(timestep_freqs)], dim=-1\n",
        "        )\n",
        "        embeddings = self.time_mlp(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "s = SinusoidalTimeEmbedding(time_embed_dim=128, scaled_time_embed_dim=256)\n",
        "timesteps = torch.tensor([1, 2, 3])\n",
        "output = s(timesteps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e4a25b1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, groupnorm_num_groups, time_embed_dim):\n",
        "        super().__init__()\n",
        "        self.time_expand = nn.Linear(time_embed_dim, out_channels)\n",
        "        self.groupnorm_1 = nn.GroupNorm(groupnorm_num_groups, in_channels)\n",
        "        self.conv_1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=3,\n",
        "            padding=\"same\",\n",
        "        )\n",
        "        self.groupnorm_2 = nn.GroupNorm(groupnorm_num_groups, out_channels)\n",
        "        self.conv_2 = nn.Conv2d(\n",
        "            in_channels=out_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=3,\n",
        "            padding=\"same\",\n",
        "        )\n",
        "        self.resize_channels = (\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1)\n",
        "            if in_channels != out_channels\n",
        "            else nn.Identity()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, time_embeddings):\n",
        "        residual_connection = x\n",
        "        time_embeddings = self.time_expand(time_embeddings)\n",
        "        x = self.groupnorm_1(x)\n",
        "        x = F.silu(x)  # @QUESTION: why do we use silu?\n",
        "        x = self.conv_1(x)\n",
        "        x = x + time_embeddings.unsqueeze(-1).unsqueeze(-1)\n",
        "        x = self.groupnorm_2(x)\n",
        "        x = F.silu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = x + self.resize_channels(residual_connection)\n",
        "        return x\n",
        "\n",
        "\n",
        "iamges = torch.randn(4, 64, 128, 128)\n",
        "time_embeddings = torch.randn(4, 256)\n",
        "rb = ResidualBlock(\n",
        "    in_channels=64, out_channels=512, groupnorm_num_groups=16, time_embed_dim=256\n",
        ")\n",
        "output = rb(iamges, time_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "51aa2d04",
      "metadata": {},
      "outputs": [],
      "source": [
        "class UpSampleBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.upsample = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=\"same\",\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.upsample(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8595b28",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cnn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
