{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5999ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c4148e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rand = torch.randn(4, 3, 64, 64)\\npred_noise = torch.randn_like(rand)\\nrandtime = torch.randint(0, 1000, (4,))\\nsampler.remove_noise(image=rand, timesteps=randtime, predicted_noise=pred_noise)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, num_steps=1000, beta_start=0.0001, beta_end=0.02):\n",
    "        self.num_steps = num_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.beta_schedule = self.linear_beta_schedule()\n",
    "        self.alpha = 1 - self.beta_schedule\n",
    "        self.alpha_cummulative_prod = torch.cumprod(self.alpha, dim=-1)\n",
    "\n",
    "    def linear_beta_schedule(self):\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.num_steps)\n",
    "\n",
    "    def _repeated_unsqueeze(self, target, tensor):\n",
    "        while target.dim() > tensor.dim():\n",
    "            tensor = tensor.unsqueeze(-1)\n",
    "        return tensor\n",
    "\n",
    "    def add_noise(self, image, timesteps):\n",
    "        batch_size, c, h, w = image.shape\n",
    "        device = image.device\n",
    "        alpha_cummulative_prod_timesteps = self.alpha_cummulative_prod[timesteps].to(\n",
    "            device\n",
    "        )\n",
    "        mean_coeff = alpha_cummulative_prod_timesteps**0.5\n",
    "        var_coeff = (1 - alpha_cummulative_prod_timesteps) ** 0.5\n",
    "        mean_coeff = self._repeated_unsqueeze(image, mean_coeff)\n",
    "        var_coeff = self._repeated_unsqueeze(image, var_coeff)\n",
    "        noise = torch.randn_like(image)\n",
    "        \"\"\"print(mean_coeff.shape)\n",
    "        print(image.shape)\"\"\"\n",
    "        noisy_image = mean_coeff * image + var_coeff * noise\n",
    "        return noisy_image, noise\n",
    "\n",
    "    def remove_noise(self, image, timesteps, predicted_noise):\n",
    "        b, c, h, w = image.shape\n",
    "        device = image.device\n",
    "        equal_to_zero_mask = timesteps == 0\n",
    "        beta_t = self.beta_schedule[timesteps].to(device)\n",
    "        alpha_t = self.alpha[timesteps].to(device)\n",
    "        alpha_cummulative_prod_t = self.alpha_cummulative_prod[timesteps].to(device)\n",
    "        alpha_cummulative_prod_t_prev = self.alpha_cummulative_prod[timesteps - 1].to(\n",
    "            device\n",
    "        )\n",
    "        alpha_cummulative_prod_t_prev[equal_to_zero_mask] = (\n",
    "            1.0  # @QUESTION: this line of code looks weird\n",
    "        )\n",
    "        noise = torch.randn_like(\n",
    "            image\n",
    "        )  # This is element z in line 4 in Algorithm 2 Sampling\n",
    "        variance = (\n",
    "            beta_t\n",
    "            * (1 - alpha_cummulative_prod_t_prev)\n",
    "            / (1 - alpha_cummulative_prod_t)\n",
    "        )  # This is element beta_t_hat in formula (7)\n",
    "        variance = self._repeated_unsqueeze(image, variance)\n",
    "        sigma_t_z = (\n",
    "            variance**0.5\n",
    "        ) * noise  # This is element sigma * z in line 4 in Algorithm 2 Sampling\n",
    "        noise_coff = (\n",
    "            beta_t / (1 - alpha_cummulative_prod_t) ** 0.5\n",
    "        )  # This is an element in line 4 in Algorithm 2 Sampling, in the paper, they write beta_t in form of (1 - alpha_t)\n",
    "        noise_coff = self._repeated_unsqueeze(image, noise_coff)\n",
    "        reciprocal_root_alpha_t = alpha_t ** (\n",
    "            -0.5\n",
    "        )  # This is the first element in Algorithm 2 Sampling\n",
    "        reciprocal_root_alpha_t = self._repeated_unsqueeze(\n",
    "            image, reciprocal_root_alpha_t\n",
    "        )\n",
    "\n",
    "        # Final formula in Algorithm 2 Sampling\n",
    "        mean = reciprocal_root_alpha_t * (image - noise_coff * predicted_noise)\n",
    "        denoised = mean + sigma_t_z\n",
    "\n",
    "        return denoised\n",
    "\n",
    "\n",
    "sampler = Sampler()\n",
    "\"\"\"rand = torch.randn(4, 3, 64, 64)\n",
    "pred_noise = torch.randn_like(rand)\n",
    "randtime = torch.randint(0, 1000, (4,))\n",
    "sampler.remove_noise(image=rand, timesteps=randtime, predicted_noise=pred_noise)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a1d745f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 14, 14])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels, num_heads=12, attn_p=0, proj_p=0):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = in_channels // num_heads\n",
    "        self.scale = self.head_dim ** (-0.5)  # 1 / sqrt(d)\n",
    "        self.query = nn.Linear(in_channels, in_channels)\n",
    "        self.key = nn.Linear(in_channels, in_channels)\n",
    "        self.value = nn.Linear(in_channels, in_channels)\n",
    "        self.attn_p = attn_p\n",
    "        self.proj = nn.Linear(in_channels, in_channels)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, embed_dim = x.shape\n",
    "        q = (\n",
    "            self.query(x)\n",
    "            .reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "            .transpose(1, 2)\n",
    "        )\n",
    "        k = (\n",
    "            self.key(x)\n",
    "            .reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "            .transpose(1, 2)\n",
    "        )\n",
    "        v = (\n",
    "            self.value(x)\n",
    "            .reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "            .transpose(1, 2)\n",
    "        )\n",
    "        x = F.scaled_dot_product_attention(q, k, v, dropout_p=self.attn_p)\n",
    "        x = x.transpose(1, 2).reshape(batch_size, seq_len, embed_dim)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        \"\"\"print(x.shape)\"\"\"\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, mlp_ratio=4, mlp_p=0):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(in_channels, in_channels * mlp_ratio)\n",
    "        self.act = nn.GELU()\n",
    "        self.drop_1 = nn.Dropout(mlp_p)\n",
    "        self.fc_2 = nn.Linear(in_channels * mlp_ratio, in_channels)\n",
    "        self.drop_2 = nn.Dropout(mlp_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.drop_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, num_heads=4, mlp_ratio=2, proj_p=0, attn_p=0, mlp_p=0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm_1 = nn.LayerNorm(\n",
    "            in_channels, eps=1e-6\n",
    "        )  # @QUESTION: what does eps mean?\n",
    "        self.attn = SelfAttention(\n",
    "            in_channels=in_channels, num_heads=num_heads, attn_p=attn_p, proj_p=proj_p\n",
    "        )\n",
    "        self.norm_2 = nn.LayerNorm(in_channels, eps=1e-6)\n",
    "        self.mlp = MLP(in_channels=in_channels, mlp_ratio=mlp_ratio, mlp_p=mlp_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape  # batch_size, channels, height, weight\n",
    "        x = x.reshape(b, c, h * w).permute(0, 2, 1)  # Swap dim 1 anf dim 2\n",
    "        x = x + self.attn(self.norm_1(x))\n",
    "        x = x + self.mlp(self.norm_2(x))\n",
    "        x = x.permute(0, 2, 1).reshape(b, c, h, w)\n",
    "        return x\n",
    "\n",
    "\n",
    "rand = torch.randn(4, 64, 14, 14)\n",
    "t = TransformerBlock(in_channels=64, num_heads=4)\n",
    "t(rand).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f9fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632cf385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
